{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center> <h1> <b>  Signal Processing (EE2000) </b> </h1> </center>\n","\n","\n","<dt> <h4>\n"," <b> Programming Assignment (01) : Digitization of Signals – Sampling and Quantization </b> </h4> </dt>\n","\n","<dt> <h4> Welcome to the first programming assignment (PA) on  Signal Processing (EE2000) course. The objective of this PA is to investigate the effects of sampling and quantization on some of the natural signals. The major objectives of this PA are as follows: </h4> </dt>\n","\n","<dd> <h4> i. Synthesizing sinusoidal signals, and observing effect of sampling on sinusoids. </dd> </h4>\n","\n","<dd> <h4> ii. Effects of sampling on audio signals, speech signals and digital images. </dd> </h4>\n","\n","<dd> <h4> iii. Effects of quantization on audio signals, speech signals and digital images </dd> </h4>\n","\n","\n","\n","\n","<dt> <h4> <b> Instructions </b> </dt> </h4>\n","\n","<dd> <h4> 1. Plagiarism is strictly prohibited. </h4> </dd>\n","\n","<dd> <h4> 2. Deadline will not be be extended under any circumstances </h4> </dd>\n","\n","<dd><h4> 3.Observations and Analysis carry significantly more weightage than just getting the correct output.</h4><dd>\n","\n","\n","[link to audio, speech and digital images required for this PA](https://drive.google.com/drive/folders/1VsDQ2GR4RXIsiiRipJGTafMsRlLpwDSv?usp=sharing)\n"],"metadata":{"id":"VTC-ZEN6uK5a"}},{"cell_type":"markdown","source":["<h4> <b> Part (a) : Synthesizing sinusoids and observing the effect of sampling on sinusoids : </b>  \n","\n","<h4> <b> Objective : </b>  \n","\n","<dt> <h4> In this experiment, you have to take a closer look at the behavior of discrete-time sinusoids from a sampling view point. Often a discrete-time signal is produced by sampling a continuous time (analog) signal, such as a constant frequency sinusoid. The relation between the frequency of the sinusoid, and the sampling frequency is the essence of the Nyquist-Shannon theorem, which requires that the sampling frequency should be at least twice the highest frequency in the signal for perfect reconstruction. In general, a continuous-time sinusoid is expressed as </h4> </dt>\n","<center> x(t) = A cos(2π$f_{0}$t + Φ) $\\hspace{5cm}$ (1) </center>\n","<dt> <h4> where A is the amplitude, $f_0$ is the frequency of the sinusoid in Hertz, t is continuous time, and φ is the phase. Since this signal is an analog signal, there are infinite values in any finite interval of time. So we cannot represent a continuous time sinusoid in a digital computer. A continuous time sinusoid has to be necessarily digitized in order to represent it in a digital computer. </h4> </dt>\n","\n","<dt> <h4> In this experiment, we synthesize discrete-time sinusoidal signals by measuring the analog signal, or in our case evaluating the sinusoid, at constant intervals of time. This is called uniform sampling, and the time interval $T_{s}$ is called the sampling period. The sampling frequency is therefore $F_{s} = \\frac{1}{T_{s}}$. The discrete-time sinusoid that is obtained by sampling the continuous time sinusoid in equation 1 at discrete instants of time t = n$T_{s}$ is given by\n","</h4> </dt>\n","\n","<center> $ x[n] = x(nT_{s}) = A cos(2πf_{0}nT_{s} + Φ) = A cos(2π\\frac{f_{0}}{f_{s}}n + Φ) $ </center>\n","\n","<dt> <h4> It is important to notice that the signal, thus generated, is a sequence of numbers, and not a continuous curve. The discrete-time signal is not defined in between any two successive time indexes, say k and k+1. It is wrong to think that the value of the discrete-time signal in between\n","two successive time indexes is zero. </h4> </dt>\n","\n","<h4> <b> Programming Questions : </b>  \n","\n","\n","<dt> <h4> i. Keeping a fixed sampling frequency of $f_s$ = 8 kHz, generate sinusoids with frequency $f_0$ = 1, 2, 3, 3.5, 4, 5, 6 and 7 kHz. Plot the sinusoids on separate figures. Why are some of these plots similar? Do they reflect the true frequency content, i.e. the frequency of the analog sinusoids? </h4> </dt>\n","\n","\n","<dt> <h4> ii. Create a new discrete-time sinusoidal signals, y[n], at the same frequencies mentioned in part (a), but sampled at a ten-fold frequency, say fs = 80 kHz, and extending over the same interval of time as x[n], i.e. if x[n] had N samples, y[n] should have 10xN samples. Plot the x[n] and y[n] sequences corresponding to the same frequency on the same figure, in a superposed fashion, using different colors. Can you now give a time-domain explanation? </h4> </dt>\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"OLHvK6lY4rew"}},{"cell_type":"code","source":["#All imports\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","#(i)\n","n  = #numpy array of discrete instants of time\n","f  = #numpy array of sinusoidal  frequencies\n","fs = #Define the sampling frequency\n","\n","plt.figure(figsize=(20,20)) #Define the figure size\n","\n","#Iterate through the frequencies and plot the sinusoids in subplots\n","for index in range(0,len(f),1):\n","    plt.subplot(4,2,index+1); #It covers a total of 8 plots\n","    #Generate the sinusoid with f[index] as frequency. You may use np.sin() function.\n","\n","    #Plot the generated sinusoidal data. Hint: plt.stem() plots the discrete data\n","\n","\n","#(ii)\n","\n"],"metadata":{"id":"RUcKDTk5d2Oz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h4> <b> Report your observations : </b>  \n","\n","<dt> <h4> i. </h4> </dt>\n","<dt> <h4> ii. </h4> </dt>\n","<dt> <h4> iii. </h4> </dt>\n","\n","\n","\n","<h4> <b> Part (b) : Effect of sampling on audio signals, speech signals and digital images : </b>\n","<h4> <b> Objective : </b>  \n","\n","<dt> <h4> In this experiment we study the effects of sampling frequency on human perception of audio/speech signals. </h4> </dt>\n","\n","<h4> <b> Programming Questions : </b>  \n","\n","<dt> <h4> i. Use Python's soundfile.read() function to read wave files. The provided music wave file is sampled at 32 kHz and speech wave file is sampled at 16 kHz. Define a downsampling rate as, say, dsr=2 and create downsampled version of the audio signal. Save or play the downsampled signal with 32000/dsr as new sampling frequency, since the signal has been downsampled by dsr. Does the music sound different? What is the audible effect of downsampling? What happens for dsr values of 2, 4, 8, 16, 32 or more? </h4> </dt>\n","<dt> <h4> Hint : Downsampling with dsr=2 can be done by taking alternative values of the signal. Similarly, we can achieve downsampling with dsr=N by taking one value in each contiguous N sample. </h4> </dt>\n","<dt> <h4> ii. Repeat part (i) for the speech signal, and note down your observations. Compare your observations with audio signals. </h4> </dt>\n","<dt> <h4> iii. Repeat sampling experiments for digital images. Hint: You can think of pixels in digital image as samples in audio / speech signals. </h4> </dt>\n","\n","\n","<h4> <b> NOTE : </b>  Code snippets to access audio, speech, and digital images are provided here for your reference. Please notice that it is not mandatory to use the same packages to load the signals. For example, if you are familiar with other packages (OpenCV) to load the signals (images), you are free to use them in this PA.\n","\n"],"metadata":{"id":"tHpWnQhJ2gb7"}},{"cell_type":"code","source":["##############################\n","#Code snippets to load and save audio / speech signals\n","##############################\n","import soundfile as sf\n","#SoundFile is an audio library that can read and write audio / speech signals.\n","#You can read more info about soundfile in https://pysoundfile.readthedocs.io/en/latest/\n","\n","#sf.read() function can be used to read the audio / speech signals from the filesystem\n","data, samplerate = sf.read('example.wav')\n","#example.wav : The location of the wavefile from where the signal needs to be loaded\n","#data : A numpy array that contains the actual values of the audio / speech signals at discrete instants of time\n","#samplerate : An integer that denotes the sampling frequency with which the signal is recorded.\n","\n","\n","##sf.read() function can be used to save the audio / speech signals in the filesystem\n","sf.write('example_save.wav', data, samplerate)\n","#example_save.wav : The path at which the signal gets saved.\n","#data : A numpy array that contains the actual values of the audio / speech signals that you are willing to save in the filesystem with the name \"example_save.wav\"\n","#data : An integer that denotes the sampling frequency with which the signal is going to be saved"],"metadata":{"id":"7k_ry27y6h6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##############################\n","#Code snippets to play audio / speech signals in google colab\n","##############################\n","from IPython.display import Audio, display\n","display(Audio('english.wav')) #Shows the audio file with button to play it.\n","#'english_norm.wav' is the filename"],"metadata":{"id":"Z7rPQRsx2u8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##############################\n","#Code snippets to mount google drive and access the files from it\n","##############################\n","import soundfile as sf\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sig,rate = sf.read('/content/drive/MyDrive/PA01/english.wav')\n","display(Audio('/content/drive/MyDrive/PA01/english.wav'))"],"metadata":{"id":"n98SuKV0n-4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mu8TfSQajele"},"outputs":[],"source":["##############################\n","#Code snippets to access image files\n","##############################\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg #You can read more info about \"matplotlib.image\" in https://matplotlib.org/stable/api/image_api.html\n","#You are free to use other packages (OpenCV, Pillow etc) to load and save the images.\n","\n","img = mpimg.imread(\"/content/drive/MyDrive/PA01/globe.jpg\")\n","#\"/content/drive/MyDrive/DSP/PA01/globe.jpg\" : location of image\n","#Shape of img : (H,W,C). By default it reads the image in 3 channel, however for gray images all the three channels will have same data. Hence we can use data in any one of the channel for experimentation.\n","\n","plt.imshow(img[:,:,0],cmap=\"gray\")\n","plt.title(\"Globe\")\n","plt.show"]},{"cell_type":"code","source":["#(i)\n","#########################################\n","#Write a function called downsample(arg1,arg2) that takes signal and the dsr as input and produces the downsampled signal.\n","#Notice that the length of downsampled signal dsr times less than the length of the original signal\n","#It is important to save the downsampled signal with sampling frequency as dsr times less than the original signal sampling frequency since the signal has been downsampled by dsr.\n","#########################################\n","def downsample(signal, rate, N):\n","    #########################################\n","    #Perform downsampling operation\n","    #########################################\n","\n","\n","    #########################################\n","    #return the downsampled signal\n","    #########################################\n","\n","#########################################\n","#Load audio / speech signals\n","#########################################\n","\n","\n","\n","#########################################\n","#Call the function downsample() with audio / speech signal and dsr as input arguments and obtain the downsampled signal\n","#########################################\n","\n","\n","#########################################\n","#plot the original signal and downsampled signal in two different subplots. Hint : You may use plt.subplot(2,1,*)\n","#########################################\n","\n","\n","\n","\n","#########################################\n","#Listen to the original and downsampled signals and report your observations\n","#########################################\n","\n","\n","\n","#########################################\n","#Repeat the experiment with different dsr values\n","#########################################\n","\n","\n","\n","#(ii)\n","#########################################\n","#Repeat part (i) for speech signal\n","#########################################\n","\n","\n","\n","\n","\n","#(ii)\n","#########################################\n","#Repeat part (i) for digital images\n","#########################################\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"3pJ0lLvEu1JG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h4> <b> Report your observations : </b>  \n","\n","<dt> <h4> i. </h4> </dt>\n","<dt> <h4> ii. </h4> </dt>\n","<dt> <h4> iii. </h4> </dt>\n","\n"],"metadata":{"id":"jCP4tDNgwTJM"}},{"cell_type":"code","source":[],"metadata":{"id":"dobqV8zpnWu3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h4> <b> Part (c) : Effect of quantization on audio signals, speech signals and digital images  : </b>  \n","<h4> <b> Objective : </b>  \n","\n","<dt> <h4>\n","So far, we have looked at the process of sampling signals. Sampling reduces the resolution in time (or space for images) from infinity to a finite number. However, the samples still have an infinite resolution in amplitude. For the case of audio signals studied above, each sample is represented as a 16-bit number. This means that there are only 65536 possible levels: in other words, the resolution in the amplitude is finite. Approximating an infinite precision real world sample measurement by a finite precision computer number is what we call quantization. Quantization leads to a loss in the signal quality, because it introduces a quantization error. In this section, we will try to develop some intuition of this phenomenon.\n","</dt> </h4>\n","\n","<h4> <b> Simulating Quantization : </b>  \n","For the purpose of studying the effects of quantization, we need an easy procedure to manually control the quantization of signals. Assuming that your signal varies in the range [a, b], one practical way of quantizing the signal to $2^N$ possible levels is the following:\n","\n","<center> $x_q = \\{\\frac{x-a}{b-a} \\cdot ( 2^{N} - 1 ) \\} \\cdot \\frac{b-a}{2^{N} - 1} + a $ </center>\n","\n","Here, N represents the number of bits to represent the sample value, and {} denotes the rounding operation. The signal range is divided into 2N levels, equally spaced, as such this procedure is called uniform quantization. The equation above (1) reduces the signal to the [0, 1] range, (2) scales the result up to the [0, $2^N$-1] range, (3) approximates values as integers (there are 2N integers in that range), and (4) moves everything back to the [a, b] range.\n","\n","<h4> <b> Programming Questions : </b>  \n","\n","<dt> <h4> i. Create a function, quantize(), that takes a vector/matrix, and N as input arguments, and returns the quantized version of each element of that vector/matrix. [ Hint: Try help np.round() ] </h4> </dt>\n","\n","<dt> <h4> ii. The supplied audio files were quantized at 16 bits per sample. Using the above function create a 4-bit quantized version of the audio files. Play the new signal. What can you say about its quality.? </h4> </dt>\n","\n","\n","<dt> <h4> iii. Now, instead of playing the quantized signal (at 4-bits), play the difference between the original audio file, and your quantized audio file. What does this sound like? Which one is better? Plot the difference signal, and try intuitively justify why the distortion caused by quantization is sometimes referred as “quantization noise”? </h4> </dt>\n","\n","<dt> <h4> iv. Repeat the parts (ii) and (iii) for 3-bit, 2-bit, and 1-bit quantized signals. Do you have any special comments on 1-bit quantization? </h4> </dt>\n","\n","\n","<dt> <h4> v. Repeat the studies on effects of quantization for the gray-scale images supplied to you. Quantize the image to 64, 32, 16, 8, 4 and 2 levels by specifying appropriate values for N. Hint : Use the relation between bits and number of levels in quantization </h4> </dt>\n","\n","\n","\n"],"metadata":{"id":"CX5n6SEfqgGl"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import soundfile as sf\n","\n","#(i)\n","#########################################\n","#Write a function called quantize(arg1,arg2) that takes signal and the target number of bits as input and produces the quantized signal.\n","#Notice that the target number of bits refers the number of bits with which your are quantizing the signal.\n","#########################################\n","def quantize(signal,N):\n","    #Notice that signal can be either 1D (audio/speech) or 2D signal.\n","    #########################################\n","    #Find maximum and minmum values of the input signal and treat them as a and b in the provided equation of quantization\n","    #########################################\n","\n","\n","\n","    #########################################\n","    #Use the appropriate formula to quantize the signal\n","    #########################################\n","\n","\n","\n","    #########################################\n","    #return the quantized signal\n","    #########################################\n","    return signal_quantize\n","\n","#(ii)\n","#########################################\n","#Load audio / speech signals\n","#########################################\n","\n","\n","\n","#########################################\n","#Call the function qunatize() with audio / speech signal and N=4 as input arguments and obtain the quantized signal\n","#########################################\n","\n","\n","\n","#########################################\n","#plot the original signal and quantized signal in two different subplots. Hint : You may use plt.subplot(2,1,*)\n","#########################################\n","\n","\n","\n","#########################################\n","#Listen to the original and qunatized signals and report your observations\n","#########################################\n","\n","\n","\n","#(iii)\n","#########################################\n","#Compute the difference between original and quantized signal.\n","#########################################\n","\n","\n","\n","#########################################\n","#Listen to quantization noise computed in the above step.\n","#########################################\n","\n","\n","\n","#########################################\n","#Plot the original signal, quantized signal and difference signal in three subplots and report your observations. Hind : plt.subplot(3,1,*)\n","#########################################\n","\n","\n","\n","#(iv)\n","#########################################\n","#Repeat part (ii) and (iii) for 3 bit, 2 bit and 1 bit and report your observations\n","#########################################\n","\n","\n","\n","#(v)\n","#########################################\n","#Load the image\n","#########################################\n","\n","\n","\n","#########################################\n","#Conduct the quantization experiments on the input image with different quantization levels\n","#########################################\n","\n","\n","\n","#########################################\n","#Plot the original image and qunatized images in subplots and report your observations.\n","#########################################\n","\n","\n","\n","\n"],"metadata":{"id":"pHdE1gAvzyBe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h4> <b> Report your observations : </b>  \n","\n","<dt> <h4> i. </h4> </dt>\n","<dt> <h4> ii. </h4> </dt>\n","<dt> <h4> iii. </h4> </dt>\n","\n"],"metadata":{"id":"7_rXPriP3IVp"}},{"cell_type":"code","source":[],"metadata":{"id":"2Rbi2J5bL58h"},"execution_count":null,"outputs":[]}]}